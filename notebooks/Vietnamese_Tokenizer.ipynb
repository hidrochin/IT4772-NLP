{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO49Ktw0Vt4Iby37l6P8zGv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hidrochin/IT4772-NLP/blob/main/notebooks/Vietnamese_Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V799h3otyrom",
        "outputId": "d5803607-37bf-48d3-d0b3-457467a23eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from pyvi) (1.6.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.12/dist-packages (from pyvi) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (3.6.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->pyvi) (0.9.11)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi import ViTokenizer, ViPosTagger\n",
        "\n",
        "ViTokenizer.tokenize(u\"Trường đại học bách khoa hà nội\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qKAUUYxPy4f9",
        "outputId": "a9d37cd1-7c5d-4075-8178-4c5e3724a58b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Trường đại_học bách_khoa hà_nội'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ViPosTagger.postagging(ViTokenizer.tokenize(u\"Trường đại học Bách Khoa Hà Nội\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBE83cMz6IKm",
        "outputId": "d91047e3-6d19-46a4-ed65-166259dc0fe5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Trường', 'đại_học', 'Bách_Khoa', 'Hà_Nội'],\n",
              " array(['N', 'N', 'Np', 'Np'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi import ViUtils\n",
        "ViUtils.remove_accents(u\"Trường đại học bách khoa hà nội\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcKToJEn6Lmk",
        "outputId": "24200977-eb30-4ce7-c519-525febefdbe2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Truong dai hoc bach khoa ha noi'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi import ViUtils\n",
        "ViUtils.add_accents(u'truong dai hoc bach khoa ha noi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NnaqWWpA6O-p",
        "outputId": "de32885d-5903-49b6-d265-5de7b97cddd1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Trường Đại học Bách Khoa hà nội'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4cee51"
      },
      "source": [
        "# Task\n",
        "Build a Vietnamese tokenizer using the maximum matching algorithm and a Vietnamese dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3868d87d"
      },
      "source": [
        "## Load vietnamese dictionary\n",
        "\n",
        "### Subtask:\n",
        "Load a Vietnamese dictionary from a file or a predefined list of words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42730501"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a list of Vietnamese words as the dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fad0150b"
      },
      "source": [
        "# vietnamese_dictionary = [\n",
        "#     \"chào\", \"buổi\", \"sáng\", \"tôi\", \"là\", \"một\", \"người\", \"việt\", \"nam\", \"yêu\",\n",
        "#     \"nước\", \"việt\", \"nam\", \"đất\", \"nước\", \"con\", \"người\", \"việt\", \"nam\", \"tuyệt\",\n",
        "#     \"vời\", \"tôi\", \"thích\", \"ăn\", \"phở\", \"bún\", \"chả\", \"nem\", \"rắn\", \"gỏi\",\n",
        "#     \"cuốn\", \"cà\", \"phê\", \"sữa\", \"đá\", \"sinh\", \"tố\", \"nước\", \"ép\", \"trái\", \"cây\",\n",
        "#     \"đi\", \"chợ\", \"mua\", \"sắm\", \"du\", \"lịch\", \"nghỉ\", \"mát\", \"hè\", \"đông\",\n",
        "#     \"xuân\", \"thu\", \"thời\", \"tiết\", \"nóng\", \"lạnh\", \"mưa\", \"nắng\", \"gió\", \"bão\",\n",
        "#     \"nhà\", \"ở\", \"thành\", \"phố\", \"hà\", \"nội\", \"hồ\", \"chí\", \"minh\", \"đà\", \"nẵng\",\n",
        "#     \"huế\", \"nha\", \"trang\", \"vũng\", \"tàu\", \"cần\", \"thơ\", \"hải\", \"phòng\", \"quảng\",\n",
        "#     \"ninh\", \"lào\", \"cai\", \"sapa\", \"đà\", \"lạt\", \"phú\", \"quốc\", \"côn\", \"đảo\",\n",
        "#     \"học\", \"tập\", \"làm\", \"việc\", \"giải\", \"trí\", \"thể\", \"thao\", \"âm\", \"nhạc\",\n",
        "#     \"điện\", \"ảnh\", \"sách\", \"báo\", \"truyện\", \"thơ\", \"văn\", \"lịch\", \"sử\", \"địa\",\n",
        "#     \"lý\", \"toán\", \"lý\", \"hóa\", \"sinh\", \"ngữ\", \"văn\", \"tiếng\", \"anh\", \"pháp\",\n",
        "#     \"đức\", \"nhật\", \"hàn\", \"trung\", \"quốc\", \"nga\", \"ý\", \"tây\", \"ban\", \"nha\",\n",
        "#     \"bồ\", \"đào\", \"nha\", \"thụy\", \"sĩ\", \"thụy\", \"điển\", \"phần\", \"lan\", \"na\", \"uy\",\n",
        "#     \"đan\", \"mạch\", \"hy\", \"lạp\", \"thổ\", \"nhĩ\", \"kỳ\", \"ấn\", \"độ\", \"thái\", \"lan\",\n",
        "#     \"cam\", \"pu\", \"chia\", \"lào\", \"myan\", \"mar\", \"phi\", \"líp\", \"pin\", \"in\", \"đô\",\n",
        "#     \"nê\", \"xi\", \"a\", \"ma\", \"lai\", \"xi\", \"a\", \"sin\", \"ga\", \"po\", \"bru\", \"nê\",\n",
        "#     \"đông\", \"ti\", \"mor\", \"úc\", \"new\", \"zea\", \"land\", \"canada\", \"usa\", \"mexico\",\n",
        "#     \"brazil\", \"argentina\", \"chile\", \"colombia\", \"peru\", \"ecuador\", \"venezuela\",\n",
        "#     \"bolivia\", \"paraguay\", \"uruguay\", \"guyana\", \"suriname\", \"pháp\", \"đức\", \"anh\",\n",
        "#     \"ý\", \"tây\", \"ban\", \"nha\", \"bồ\", \"đào\", \"nha\", \"nga\", \"úc\", \"canada\", \"mỹ\",\n",
        "#     \"nhật\", \"bản\", \"hàn\", \"quốc\", \"ấn\", \"độ\", \"trung\", \"quốc\", \"brazil\", \"mexico\",\n",
        "#     \"indonesia\", \"pakistan\", \"nigeria\", \"bangladesh\", \"nga\", \"nhật\", \"đức\", \"anh\",\n",
        "#     \"pháp\", \"ý\", \"tây\", \"ban\", \"nha\", \"bồ\", \"đào\", \"nha\", \"úc\", \"canada\", \"mỹ\",\n",
        "#     \"nhật\", \"bản\", \"hàn\", \"quốc\", \"ấn\", \"độ\", \"trung\", \"quốc\", \"brazil\", \"mexico\",\n",
        "#     \"indonesia\", \"pakistan\", \"nigeria\", \"bangladesh\", \"nga\", \"nhật\", \"đức\", \"anh\",\n",
        "#     \"pháp\", \"ý\", \"tây\", \"ban\", \"nha\", \"bồ\", \"đào\", \"nha\", \"úc\", \"canada\", \"mỹ\",\n",
        "#     \"nhật\", \"bản\", \"hàn\", \"quốc\", \"ấn\", \"độ\", \"trung\", \"quốc\", \"brazil\", \"mexico\",\n",
        "#     \"indonesia\", \"pakistan\", \"nigeria\", \"bangladesh\"\n",
        "# ]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"npvinHnivqn/VietnameseDictionary\")"
      ],
      "metadata": {
        "id": "8EnbQEvQz9tO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8HKUih95FLE",
        "outputId": "d404e3d8-b787-4009-e4cc-93eb0ccdc208"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['từ', 'định nghĩa'],\n",
              "        num_rows: 30158\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing and create Vietnamese dictionary from ds\n",
        "\n",
        "# Extract words from the dataset, replacing spaces with underscores and handling None values.\n",
        "vietnamese_dictionary = [word.replace(\" \", \"_\") for word in ds['train']['từ'] if word is not None]\n",
        "\n",
        "# Optional: Further preprocessing if needed, e.g., converting to lowercase\n",
        "# vietnamese_dictionary = [word.lower() for word in vietnamese_dictionary]\n",
        "\n",
        "print(f\"Created a dictionary with {len(vietnamese_dictionary)} words.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prFCf4E64xGw",
        "outputId": "a0c14c82-b3e7-45f1-ec90-ba646ebdae04"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a dictionary with 30157 words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vietnamese_dictionary[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubNgypTd6rv4",
        "outputId": "6bdbabfe-9acf-47dd-a547-597953d1ce97"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'a_dua', 'a_hoàn', 'a_phiến', 'a_tòng', 'à', 'ả', 'ả_đào', 'á', 'á_khẩu']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "194b2ece"
      },
      "source": [
        "## Implement maximum matching algorithm\n",
        "\n",
        "### Subtask:\n",
        "Implement the maximum matching algorithm to tokenize the input text based on the loaded dictionary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba07e4e"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the maximum matching tokenization function as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9702f26"
      },
      "source": [
        "def max_matching_tokenizer(text, dictionary):\n",
        "    \"\"\"\n",
        "    Tokenizes a given text using the maximum matching algorithm and a dictionary.\n",
        "\n",
        "    Args:\n",
        "        text: The input string to tokenize.\n",
        "        dictionary: A list of words representing the dictionary.\n",
        "\n",
        "    Returns:\n",
        "        A list of tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        longest_match = None\n",
        "        for j in range(len(text), i - 1, -1):\n",
        "            word = text[i:j]\n",
        "            if word in dictionary:\n",
        "                longest_match = word\n",
        "                break\n",
        "        if longest_match:\n",
        "            tokens.append(longest_match)\n",
        "            i += len(longest_match)\n",
        "        else:\n",
        "            tokens.append(text[i])\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "252a88b7"
      },
      "source": [
        "## Test the tokenizer\n",
        "\n",
        "### Subtask:\n",
        "Test the implemented tokenizer with sample Vietnamese text to verify its correctness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afc1634d"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a sample Vietnamese text, call the tokenizer function, and print the result to verify the implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85f7919f",
        "outputId": "af6d1ca7-ef68-4203-cdf8-12d2a56bfe40"
      },
      "source": [
        "# 1. Define a sample Vietnamese text string\n",
        "sample_text = \"chàobuổisángtôilàmộtngườiviệtnam\"\n",
        "\n",
        "# 2. Call the max_matching_tokenizer function\n",
        "tokens = max_matching_tokenizer(sample_text, vietnamese_dictionary)\n",
        "\n",
        "# 3. Print the resulting list of tokens\n",
        "print(tokens)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chào', 'buổi', 'sáng', 'tôi', 'làm', 'ộ', 't', 'người', 'v', 'i', 'ệ', 't', 'nam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53daa579"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The Vietnamese dictionary was successfully loaded as a Python list containing a predefined set of words.\n",
        "*   The `max_matching_tokenizer` function was implemented, which tokenizes text by finding the longest possible word matches from the dictionary.\n",
        "*   Testing the tokenizer with the sample text \"chàobuổisángtôilàmộtngườiviệtnam\" resulted in the tokenized list `['chào', 'buổi', 'sáng', 'tôi', 'làm', 'ộ', 't', 'người', 'việt', 'nam']`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current tokenizer may not handle words not present in the dictionary effectively, leading to single-character tokens for unknown parts of the text (e.g., 'ộ', 't' in the example). Expanding the dictionary or incorporating a fallback mechanism for out-of-vocabulary words could improve performance.\n",
        "*   The tokenizer does not currently handle punctuation or capitalization. Adding preprocessing steps to normalize the text could enhance the tokenization accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OF7iJ6hV54-o"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}